Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:05<02:32,  5.26s/it]Loading checkpoint shards:   7%|▋         | 2/30 [00:09<02:10,  4.68s/it]Loading checkpoint shards:  10%|█         | 3/30 [00:14<02:06,  4.68s/it]Loading checkpoint shards:  13%|█▎        | 4/30 [00:18<01:59,  4.59s/it]Loading checkpoint shards:  17%|█▋        | 5/30 [00:22<01:51,  4.46s/it]Loading checkpoint shards:  20%|██        | 6/30 [00:28<01:54,  4.76s/it]Loading checkpoint shards:  23%|██▎       | 7/30 [00:32<01:45,  4.57s/it]Loading checkpoint shards:  27%|██▋       | 8/30 [00:36<01:39,  4.54s/it]Loading checkpoint shards:  30%|███       | 9/30 [00:41<01:34,  4.50s/it]Loading checkpoint shards:  33%|███▎      | 10/30 [00:46<01:35,  4.80s/it]Loading checkpoint shards:  37%|███▋      | 11/30 [00:50<01:27,  4.58s/it]Loading checkpoint shards:  40%|████      | 12/30 [00:54<01:19,  4.43s/it]Loading checkpoint shards:  43%|████▎     | 13/30 [00:59<01:15,  4.41s/it]Loading checkpoint shards:  47%|████▋     | 14/30 [01:04<01:12,  4.55s/it]Loading checkpoint shards:  50%|█████     | 15/30 [01:08<01:05,  4.39s/it]Loading checkpoint shards:  53%|█████▎    | 16/30 [01:12<01:00,  4.31s/it]Loading checkpoint shards:  57%|█████▋    | 17/30 [01:16<00:55,  4.25s/it]Loading checkpoint shards:  60%|██████    | 18/30 [01:21<00:53,  4.42s/it]Loading checkpoint shards:  63%|██████▎   | 19/30 [01:26<00:52,  4.73s/it]Loading checkpoint shards:  67%|██████▋   | 20/30 [01:30<00:45,  4.53s/it]Loading checkpoint shards:  70%|███████   | 21/30 [01:34<00:39,  4.41s/it]Loading checkpoint shards:  73%|███████▎  | 22/30 [01:38<00:34,  4.31s/it]Loading checkpoint shards:  77%|███████▋  | 23/30 [01:43<00:30,  4.31s/it]Loading checkpoint shards:  80%|████████  | 24/30 [01:47<00:25,  4.32s/it]Loading checkpoint shards:  83%|████████▎ | 25/30 [01:51<00:21,  4.26s/it]Loading checkpoint shards:  87%|████████▋ | 26/30 [01:55<00:16,  4.24s/it]Loading checkpoint shards:  90%|█████████ | 27/30 [02:00<00:12,  4.19s/it]Loading checkpoint shards:  93%|█████████▎| 28/30 [02:04<00:08,  4.29s/it]Loading checkpoint shards:  97%|█████████▋| 29/30 [02:08<00:04,  4.31s/it]Loading checkpoint shards: 100%|██████████| 30/30 [02:10<00:00,  3.62s/it]Loading checkpoint shards: 100%|██████████| 30/30 [02:10<00:00,  4.36s/it]
get_com_directions:   0%|          | 0/80 [00:00<?, ?it/s]get_com_directions:   1%|▏         | 1/80 [00:00<00:08,  8.85it/s]get_com_directions:   2%|▎         | 2/80 [00:00<00:08,  8.69it/s]get_com_directions:   4%|▍         | 3/80 [00:00<00:08,  8.76it/s]get_com_directions:   5%|▌         | 4/80 [00:00<00:08,  8.86it/s]get_com_directions:   6%|▋         | 5/80 [00:00<00:08,  8.90it/s]get_com_directions:   8%|▊         | 6/80 [00:00<00:08,  8.99it/s]get_com_directions:   9%|▉         | 7/80 [00:00<00:08,  9.04it/s]get_com_directions:  10%|█         | 8/80 [00:00<00:07,  9.08it/s]get_com_directions:  11%|█▏        | 9/80 [00:00<00:07,  9.16it/s]get_com_directions:  12%|█▎        | 10/80 [00:01<00:07,  9.21it/s]get_com_directions:  14%|█▍        | 11/80 [00:01<00:07,  9.22it/s]get_com_directions:  15%|█▌        | 12/80 [00:01<00:07,  9.24it/s]get_com_directions:  16%|█▋        | 13/80 [00:01<00:07,  9.27it/s]get_com_directions:  18%|█▊        | 14/80 [00:01<00:07,  9.32it/s]get_com_directions:  19%|█▉        | 15/80 [00:01<00:06,  9.35it/s]get_com_directions:  20%|██        | 16/80 [00:01<00:06,  9.38it/s]get_com_directions:  21%|██▏       | 17/80 [00:01<00:06,  9.40it/s]get_com_directions:  22%|██▎       | 18/80 [00:01<00:06,  9.42it/s]get_com_directions:  24%|██▍       | 19/80 [00:02<00:06,  9.44it/s]get_com_directions:  25%|██▌       | 20/80 [00:02<00:06,  9.45it/s]get_com_directions:  26%|██▋       | 21/80 [00:02<00:06,  9.46it/s]get_com_directions:  28%|██▊       | 22/80 [00:02<00:06,  9.46it/s]get_com_directions:  29%|██▉       | 23/80 [00:02<00:06,  9.46it/s]get_com_directions:  30%|███       | 24/80 [00:02<00:05,  9.46it/s]get_com_directions:  31%|███▏      | 25/80 [00:02<00:05,  9.47it/s]get_com_directions:  32%|███▎      | 26/80 [00:02<00:05,  9.46it/s]get_com_directions:  34%|███▍      | 27/80 [00:02<00:05,  9.47it/s]get_com_directions:  35%|███▌      | 28/80 [00:03<00:05,  9.47it/s]get_com_directions:  36%|███▋      | 29/80 [00:03<00:05,  9.47it/s]get_com_directions:  38%|███▊      | 30/80 [00:03<00:05,  9.47it/s]get_com_directions:  39%|███▉      | 31/80 [00:03<00:05,  9.48it/s]get_com_directions:  40%|████      | 32/80 [00:03<00:05,  9.49it/s]get_com_directions:  41%|████▏     | 33/80 [00:03<00:04,  9.49it/s]get_com_directions:  42%|████▎     | 34/80 [00:03<00:04,  9.49it/s]get_com_directions:  44%|████▍     | 35/80 [00:03<00:04,  9.49it/s]get_com_directions:  45%|████▌     | 36/80 [00:03<00:04,  9.49it/s]get_com_directions:  46%|████▋     | 37/80 [00:03<00:04,  9.49it/s]get_com_directions:  48%|████▊     | 38/80 [00:04<00:04,  9.48it/s]get_com_directions:  49%|████▉     | 39/80 [00:04<00:04,  9.48it/s]get_com_directions:  50%|█████     | 40/80 [00:04<00:04,  9.48it/s]get_com_directions:  51%|█████▏    | 41/80 [00:04<00:04,  9.48it/s]get_com_directions:  52%|█████▎    | 42/80 [00:04<00:04,  9.47it/s]get_com_directions:  54%|█████▍    | 43/80 [00:04<00:03,  9.47it/s]get_com_directions:  55%|█████▌    | 44/80 [00:04<00:03,  9.47it/s]get_com_directions:  56%|█████▋    | 45/80 [00:04<00:03,  9.47it/s]get_com_directions:  57%|█████▊    | 46/80 [00:04<00:03,  9.47it/s]get_com_directions:  59%|█████▉    | 47/80 [00:05<00:03,  9.44it/s]get_com_directions:  60%|██████    | 48/80 [00:05<00:03,  9.43it/s]get_com_directions:  61%|██████▏   | 49/80 [00:05<00:03,  9.44it/s]get_com_directions:  62%|██████▎   | 50/80 [00:05<00:03,  9.44it/s]get_com_directions:  64%|██████▍   | 51/80 [00:05<00:03,  9.43it/s]get_com_directions:  65%|██████▌   | 52/80 [00:05<00:02,  9.44it/s]get_com_directions:  66%|██████▋   | 53/80 [00:05<00:02,  9.45it/s]get_com_directions:  68%|██████▊   | 54/80 [00:05<00:02,  9.46it/s]get_com_directions:  69%|██████▉   | 55/80 [00:05<00:02,  9.45it/s]get_com_directions:  70%|███████   | 56/80 [00:05<00:02,  9.45it/s]get_com_directions:  71%|███████▏  | 57/80 [00:06<00:02,  9.46it/s]get_com_directions:  72%|███████▎  | 58/80 [00:06<00:02,  9.46it/s]get_com_directions:  74%|███████▍  | 59/80 [00:06<00:02,  9.46it/s]get_com_directions:  75%|███████▌  | 60/80 [00:06<00:02,  9.46it/s]get_com_directions:  76%|███████▋  | 61/80 [00:06<00:02,  9.47it/s]get_com_directions:  78%|███████▊  | 62/80 [00:06<00:01,  9.45it/s]get_com_directions:  79%|███████▉  | 63/80 [00:06<00:01,  9.44it/s]get_com_directions:  80%|████████  | 64/80 [00:06<00:01,  9.44it/s]get_com_directions:  81%|████████▏ | 65/80 [00:06<00:01,  9.45it/s]get_com_directions:  82%|████████▎ | 66/80 [00:07<00:01,  9.42it/s]get_com_directions:  84%|████████▍ | 67/80 [00:07<00:01,  9.43it/s]get_com_directions:  85%|████████▌ | 68/80 [00:07<00:01,  9.45it/s]get_com_directions:  86%|████████▋ | 69/80 [00:07<00:01,  9.46it/s]get_com_directions:  88%|████████▊ | 70/80 [00:07<00:01,  9.46it/s]get_com_directions:  89%|████████▉ | 71/80 [00:07<00:00,  9.46it/s]get_com_directions:  90%|█████████ | 72/80 [00:07<00:00,  9.47it/s]get_com_directions:  91%|█████████▏| 73/80 [00:07<00:00,  9.49it/s]get_com_directions:  92%|█████████▎| 74/80 [00:07<00:00,  9.49it/s]get_com_directions:  94%|█████████▍| 75/80 [00:07<00:00,  9.50it/s]get_com_directions:  95%|█████████▌| 76/80 [00:08<00:00,  9.50it/s]get_com_directions:  96%|█████████▋| 77/80 [00:08<00:00,  9.50it/s]get_com_directions:  98%|█████████▊| 78/80 [00:08<00:00,  9.51it/s]get_com_directions:  99%|█████████▉| 79/80 [00:08<00:00,  9.51it/s]get_com_directions: 100%|██████████| 80/80 [00:08<00:00,  9.51it/s]get_com_directions: 100%|██████████| 80/80 [00:08<00:00,  9.40it/s]
train_probes:   0%|          | 0/80 [00:00<?, ?it/s]train_probes:   1%|▏         | 1/80 [00:00<00:39,  2.01it/s]train_probes:   2%|▎         | 2/80 [00:00<00:38,  2.03it/s]train_probes:   4%|▍         | 3/80 [00:01<00:37,  2.03it/s]train_probes:   5%|▌         | 4/80 [00:02<00:38,  1.99it/s]train_probes:   6%|▋         | 5/80 [00:02<00:38,  1.95it/s]train_probes:   8%|▊         | 6/80 [00:03<00:37,  1.99it/s]train_probes:   9%|▉         | 7/80 [00:03<00:36,  2.02it/s]train_probes:  10%|█         | 8/80 [00:03<00:35,  2.03it/s]train_probes:  11%|█▏        | 9/80 [00:04<00:35,  2.00it/s]train_probes:  12%|█▎        | 10/80 [00:05<00:35,  1.98it/s]train_probes:  14%|█▍        | 11/80 [00:05<00:34,  2.00it/s]train_probes:  15%|█▌        | 12/80 [00:05<00:33,  2.02it/s]train_probes:  16%|█▋        | 13/80 [00:06<00:33,  1.98it/s]train_probes:  18%|█▊        | 14/80 [00:07<00:36,  1.81it/s]train_probes:  19%|█▉        | 15/80 [00:07<00:39,  1.66it/s]train_probes:  20%|██        | 16/80 [00:08<00:40,  1.57it/s]train_probes:  21%|██▏       | 17/80 [00:09<00:42,  1.50it/s]train_probes:  22%|██▎       | 18/80 [00:10<00:42,  1.46it/s]train_probes:  24%|██▍       | 19/80 [00:10<00:43,  1.40it/s]train_probes:  25%|██▌       | 20/80 [00:11<00:40,  1.48it/s]train_probes:  26%|██▋       | 21/80 [00:12<00:41,  1.43it/s]train_probes:  28%|██▊       | 22/80 [00:12<00:40,  1.42it/s]train_probes:  29%|██▉       | 23/80 [00:13<00:40,  1.40it/s]train_probes:  30%|███       | 24/80 [00:14<00:40,  1.38it/s]train_probes:  31%|███▏      | 25/80 [00:15<00:39,  1.38it/s]train_probes:  32%|███▎      | 26/80 [00:15<00:39,  1.37it/s]train_probes:  34%|███▍      | 27/80 [00:16<00:35,  1.51it/s]train_probes:  35%|███▌      | 28/80 [00:16<00:33,  1.55it/s]train_probes:  36%|███▋      | 29/80 [00:17<00:33,  1.54it/s]train_probes:  38%|███▊      | 30/80 [00:18<00:33,  1.50it/s]train_probes:  39%|███▉      | 31/80 [00:18<00:31,  1.54it/s]train_probes:  40%|████      | 32/80 [00:19<00:29,  1.65it/s]train_probes:  41%|████▏     | 33/80 [00:20<00:28,  1.67it/s]train_probes:  42%|████▎     | 34/80 [00:20<00:27,  1.70it/s]train_probes:  44%|████▍     | 35/80 [00:21<00:26,  1.71it/s]train_probes:  45%|████▌     | 36/80 [00:21<00:25,  1.70it/s]train_probes:  46%|████▋     | 37/80 [00:22<00:25,  1.69it/s]train_probes:  48%|████▊     | 38/80 [00:23<00:26,  1.61it/s]train_probes:  49%|████▉     | 39/80 [00:23<00:26,  1.58it/s]train_probes:  50%|█████     | 40/80 [00:24<00:24,  1.62it/s]train_probes:  51%|█████▏    | 41/80 [00:24<00:23,  1.64it/s]train_probes:  52%|█████▎    | 42/80 [00:25<00:24,  1.54it/s]train_probes:  54%|█████▍    | 43/80 [00:26<00:23,  1.56it/s]train_probes:  55%|█████▌    | 44/80 [00:27<00:24,  1.47it/s]train_probes:  56%|█████▋    | 45/80 [00:27<00:22,  1.54it/s]train_probes:  57%|█████▊    | 46/80 [00:28<00:22,  1.50it/s]train_probes:  59%|█████▉    | 47/80 [00:28<00:20,  1.60it/s]train_probes:  60%|██████    | 48/80 [00:29<00:20,  1.56it/s]train_probes:  61%|██████▏   | 49/80 [00:30<00:19,  1.59it/s]train_probes:  62%|██████▎   | 50/80 [00:30<00:19,  1.52it/s]train_probes:  64%|██████▍   | 51/80 [00:31<00:19,  1.52it/s]train_probes:  65%|██████▌   | 52/80 [00:32<00:19,  1.46it/s]train_probes:  66%|██████▋   | 53/80 [00:32<00:17,  1.55it/s]train_probes:  68%|██████▊   | 54/80 [00:33<00:17,  1.47it/s]train_probes:  69%|██████▉   | 55/80 [00:34<00:17,  1.45it/s]train_probes:  70%|███████   | 56/80 [00:35<00:17,  1.40it/s]train_probes:  71%|███████▏  | 57/80 [00:35<00:16,  1.41it/s]train_probes:  72%|███████▎  | 58/80 [00:36<00:15,  1.46it/s]train_probes:  74%|███████▍  | 59/80 [00:37<00:14,  1.42it/s]train_probes:  75%|███████▌  | 60/80 [00:37<00:13,  1.47it/s]train_probes:  76%|███████▋  | 61/80 [00:38<00:12,  1.54it/s]train_probes:  78%|███████▊  | 62/80 [00:38<00:11,  1.56it/s]train_probes:  79%|███████▉  | 63/80 [00:39<00:10,  1.63it/s]train_probes:  80%|████████  | 64/80 [00:40<00:10,  1.55it/s]train_probes:  81%|████████▏ | 65/80 [00:40<00:10,  1.47it/s]train_probes:  82%|████████▎ | 66/80 [00:41<00:08,  1.61it/s]train_probes:  84%|████████▍ | 67/80 [00:42<00:08,  1.49it/s]train_probes:  85%|████████▌ | 68/80 [00:43<00:08,  1.41it/s]train_probes:  86%|████████▋ | 69/80 [00:43<00:07,  1.50it/s]train_probes:  88%|████████▊ | 70/80 [00:44<00:06,  1.44it/s]train_probes:  89%|████████▉ | 71/80 [00:45<00:06,  1.47it/s]train_probes:  90%|█████████ | 72/80 [00:45<00:05,  1.50it/s]train_probes:  91%|█████████▏| 73/80 [00:46<00:04,  1.53it/s]train_probes:  92%|█████████▎| 74/80 [00:46<00:03,  1.53it/s]train_probes:  94%|█████████▍| 75/80 [00:47<00:03,  1.53it/s]train_probes:  95%|█████████▌| 76/80 [00:48<00:02,  1.54it/s]train_probes:  96%|█████████▋| 77/80 [00:49<00:02,  1.44it/s]train_probes:  98%|█████████▊| 78/80 [00:49<00:01,  1.49it/s]train_probes:  99%|█████████▉| 79/80 [00:50<00:00,  1.47it/s]train_probes: 100%|██████████| 80/80 [00:51<00:00,  1.44it/s]train_probes: 100%|██████████| 80/80 [00:51<00:00,  1.57it/s]
tqa_run_answers:   0%|          | 0/409 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
tqa_run_answers:   0%|          | 1/409 [00:20<2:19:28, 20.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   0%|          | 2/409 [00:24<1:11:16, 10.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   1%|          | 3/409 [00:27<49:27,  7.31s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   1%|          | 4/409 [00:31<39:12,  5.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   1%|          | 5/409 [00:34<33:30,  4.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   1%|▏         | 6/409 [00:38<30:03,  4.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   2%|▏         | 7/409 [00:41<27:51,  4.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   2%|▏         | 8/409 [00:45<26:23,  3.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   2%|▏         | 9/409 [00:48<25:23,  3.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   2%|▏         | 10/409 [00:52<24:42,  3.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   3%|▎         | 11/409 [00:55<24:12,  3.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   3%|▎         | 12/409 [00:59<23:51,  3.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   3%|▎         | 13/409 [01:02<23:35,  3.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   3%|▎         | 14/409 [01:06<23:23,  3.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   4%|▎         | 15/409 [01:09<23:14,  3.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   4%|▍         | 16/409 [01:13<23:07,  3.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   4%|▍         | 17/409 [01:16<23:00,  3.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   4%|▍         | 18/409 [01:20<22:55,  3.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   5%|▍         | 19/409 [01:23<22:50,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   5%|▍         | 20/409 [01:27<22:45,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   5%|▌         | 21/409 [01:30<22:46,  3.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   5%|▌         | 22/409 [01:34<22:41,  3.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   6%|▌         | 23/409 [01:37<22:35,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   6%|▌         | 24/409 [01:41<22:31,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   6%|▌         | 25/409 [01:44<22:27,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   6%|▋         | 26/409 [01:48<22:23,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   7%|▋         | 27/409 [01:51<22:19,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   7%|▋         | 28/409 [01:55<22:15,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   7%|▋         | 29/409 [01:58<22:11,  3.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   7%|▋         | 30/409 [02:02<22:07,  3.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   8%|▊         | 31/409 [02:05<22:04,  3.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   8%|▊         | 32/409 [02:09<22:00,  3.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   8%|▊         | 33/409 [02:12<21:57,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   8%|▊         | 34/409 [02:16<21:54,  3.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   9%|▊         | 35/409 [02:19<21:50,  3.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   9%|▉         | 36/409 [02:23<21:50,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   9%|▉         | 37/409 [02:26<21:45,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:   9%|▉         | 38/409 [02:30<21:41,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:  10%|▉         | 39/409 [02:33<21:37,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:  10%|▉         | 40/409 [02:37<21:33,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:  10%|█         | 41/409 [02:40<21:29,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:  10%|█         | 42/409 [02:44<21:25,  3.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:  11%|█         | 43/409 [02:47<21:22,  3.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:  11%|█         | 44/409 [02:51<21:18,  3.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
tqa_run_answers:  11%|█         | 45/409 [02:54<21:15,  3.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
